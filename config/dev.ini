[General]
DATA_FOLDER = /Users/raksingh/personal/github/my-gen-ai-apps/data
DB_PATH = /Users/raksingh/personal/github/my-gen-ai-apps/db/chroma_db
LOG_LEVEL = DEBUG 
LOG_FILE = /Users/raksingh/personal/github/my-ollama-rag-app/logs/app.log 
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
EMBEDDING_MODEL = mxbai-embed-large
MODEL = llama3.2
MODEL_PROVIDER = 'ollama'
[Logging]
level = DEBUG
file = /Users/raksingh/personal/github/my-ollama-rag-app/logs/app.log
format = %(asctime)s - %(name)s - %(levelname)s - %(message)s       
[Ollama]
ollama_api_url = http://localhost:11434
ollama_model = llama3.2
[Embedding]
embed_model_name = sentence-transformers/all-MiniLM-L12-v2
embed_model_url = https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L12-v2
embed_model_type = sentence-transformers/all-MiniLM-L12-v2
embed_model_params = {"normalize_embeddings": true, "batch_size": 32, "device": "cpu"}
[Retrieval]
retriever_model = rag_retriever
retriever_params = {"k": 5, "similarity_threshold": 0.7}
retriever_url = http://localhost:11434/rag_retriever                            
[Chain]
chain_model = rag_chain
chain_params = {"max_length": 512, "temperature": 0.7, "top_p": 0.9}
chain_url = http://localhost:11434/rag_chain
[Session]
session_id = 12345678-1234-5678-1234-567812345678
session_history_file = /Users/raksingh/personal/github/my-ollama-rag-app/sessions/session_history.json
session_timeout = 3600  ; in seconds
session_max_length = 1000  ; max number of messages in session history
session_save_interval = 300  ; in seconds
session_load_on_start = true
session_save_on_exit = true
session_cleanup_interval = 600  ; in seconds            
[Docs]
docs_folder = /Users/raksingh/personal/github/my-ollama-rag-app/data/docs
docs_db_path = /Users/raksingh/personal/github/my-ollama-rag-app/db/docs.db
docs_chunk_size = 512  ; size of each document chunk
docs_chunk_overlap = 50  ; overlap between document chunks
docs_split_method = "sentence"  ; method to split documents (e.g., "sentence", "paragraph", "fixed")
docs_embed_model = sentence-transformers/all-MiniLM-L12-v2
docs_embed_batch_size = 32  ; batch size for embedding documents
docs_embed_device = "cpu"  ; device to use for embedding (e.g., "cpu", "cuda")
docs_retriever_k = 5  ; number of documents to retrieve
docs_retriever_similarity_threshold = 0.7  ; similarity threshold for document retrieval
docs_retriever_model = rag_retriever
docs_retriever_url = http://localhost:11434/rag_retriever
docs_chain_model = rag_chain
docs_chain_params = {"max_length": 512, "temperature": 0.7, "top_p": 0.9}
docs_chain_url = http://localhost:11434/rag_chain
docs_db_init = true  ; whether to initialize the database on startup            

[Database]
db_host = localhost
db_port = 5432
db_user = ollama_user
db_password = ollama_password
db_name = ollama_db
db_connection_timeout = 30  ; in seconds
db_max_connections = 10  ; maximum number of database connections
db_pool_size = 5  ; size of the connection pool     