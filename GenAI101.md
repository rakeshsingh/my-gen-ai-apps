
## Generative AI 101

### Q. what is an LLM? 
"LLM" stands for "Large Language Model." "Large" means it's really big and knows a lot of information. "Language" means it understands words and how to use them. And "Model" is just a fancy word for a computer program that can learn patterns. An LLM reads millions and millions of books, websites, and articles all at once to learn how people write and talk. After reading all that stuff, the LLM becomes really good at understanding what you're asking and can write back to you in a way that makes sense. It's kind of like having a super-smart friend who has read every book in the world and can help you with questions or write stories with you.

### Q. What is Generative pre-trained transfomer?
A generative pre-trained transformer (GPT) is a type of large language model (LLM) and a prominent framework for generative artificial intelligence.It is an artificial neural network that is used in natural language processing. It is based on the transformer deep learning architecture, pre-trained on large data sets of unlabeled text, and able to generate novel human-like content.

### Q. What is Retrieval Augmented Generation (RAG)? 
Retrieval Augmented Generation (RAG) is a technique that enhances Large Language Models (LLMs) by integrating an external knowledge base during the generation process. Instead of relying solely on the LLM's pre-trained data, RAG enables it to access and incorporate information from specific documents, websites, or databases to provide more accurate, up-to-date, and contextually relevant responses.
